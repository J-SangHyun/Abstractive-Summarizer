# -*- coding: utf-8 -*-


class Tokenizer(object):
    def __init__(self, name):
        self.name = name

    def tokenize(self, sentence):
        pass

    def encode(self, sentence, max_length):
        pass

    def decode(self, indexes):
        pass
